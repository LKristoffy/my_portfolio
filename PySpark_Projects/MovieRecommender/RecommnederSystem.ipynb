{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpark Implementation of a Movie Recommender System\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project shows the efficient and distributed loading of the MovieLens Dataset using pyspark, as well as some basic EDA and using alternating least squares (ALS) to train a collaborative filtering model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: findspark\n",
      "Version: 2.0.1\n",
      "Summary: Find pyspark to make it importable.\n",
      "Home-page: https://github.com/minrk/findspark\n",
      "Author: Min RK\n",
      "Author-email: benjaminrk@gmail.com\n",
      "License: BSD (3-clause)\n",
      "Location: /Users/liamkristoffy/anaconda3/envs/pyspark_env/lib/python3.9/site-packages\n",
      "Requires: \n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip show findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/liamkristoffy/anaconda3/envs/pyspark_env/lib/python3.9/site-packages/pyspark'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/21 21:26:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      "\n",
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"Movie Recommendation System\").config(\"spark.executor.memory\", \"8g\").config(\"spark.driver.memory\", \"8g\").getOrCreate()\n",
    "\n",
    "# Load Ratings and Movies Data\n",
    "ratings = spark.read.csv(\"Data/rating.csv\", header=True, inferSchema=True)\n",
    "movies = spark.read.csv(\"Data/movie.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Show schema\n",
    "ratings.printSchema()\n",
    "movies.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(userId=1, movieId=2, rating=3.5, timestamp=datetime.datetime(2005, 4, 2, 23, 53, 47)),\n",
       " Row(userId=1, movieId=29, rating=3.5, timestamp=datetime.datetime(2005, 4, 2, 23, 31, 16)),\n",
       " Row(userId=1, movieId=32, rating=3.5, timestamp=datetime.datetime(2005, 4, 2, 23, 33, 39)),\n",
       " Row(userId=1, movieId=47, rating=3.5, timestamp=datetime.datetime(2005, 4, 2, 23, 32, 7)),\n",
       " Row(userId=1, movieId=50, rating=3.5, timestamp=datetime.datetime(2005, 4, 2, 23, 29, 40))]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:===================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+------------------+\n",
      "|summary|           userId|           movieId|            rating|\n",
      "+-------+-----------------+------------------+------------------+\n",
      "|  count|         20000263|          20000263|          20000263|\n",
      "|   mean|69045.87258292554| 9041.567330339605|3.5255285642993797|\n",
      "| stddev|40038.62665316145|19789.477445413166|1.0519889192942444|\n",
      "|    min|                1|                 1|               0.5|\n",
      "|    max|           138493|            131262|               5.0|\n",
      "+-------+-----------------+------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "ratings.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 138493, Number of movies: 26744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|movieId|        avg_rating|\n",
      "+-------+------------------+\n",
      "|   3997|2.0703468490473864|\n",
      "|   1580|  3.55831928049466|\n",
      "|   3918| 2.918940609951846|\n",
      "|   2366|3.5492681454655197|\n",
      "|   3175| 3.600717102904267|\n",
      "+-------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 24:====================================>                     (5 + 3) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+--------------------+------------------+\n",
      "|movieId|avg_rating|               title|            genres|\n",
      "+-------+----------+--------------------+------------------+\n",
      "| 130644|       5.0|The Garden of Sin...|         Animation|\n",
      "| 126945|       5.0|  Small Roads (2011)|(no genres listed)|\n",
      "| 129530|       5.0|Slingshot Hip Hop...|(no genres listed)|\n",
      "|  32230|       5.0|Snow Queen, The (...|  Children|Fantasy|\n",
      "| 129036|       5.0|People of the Win...|       Documentary|\n",
      "+-------+----------+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Check number of unique users and movies\n",
    "num_users = ratings.select(\"userId\").distinct().count()\n",
    "num_movies = ratings.select(\"movieId\").distinct().count()\n",
    "print(f\"Number of users: {num_users}, Number of movies: {num_movies}\")\n",
    "\n",
    "# Average rating per movie\n",
    "avg_ratings = ratings.groupBy(\"movieId\").avg(\"rating\").withColumnRenamed(\"avg(rating)\", \"avg_rating\")\n",
    "avg_ratings.show(5)\n",
    "\n",
    "# Join with movies to get titles\n",
    "avg_ratings_with_titles = avg_ratings.join(movies, \"movieId\")\n",
    "avg_ratings_with_titles.orderBy(col(\"avg_rating\").desc()).show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train, test = ratings.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.repartition(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure ALS model\n",
    "als = ALS(\n",
    "    maxIter=10, \n",
    "    regParam=0.01,\n",
    "    userCol=\"userId\", \n",
    "    itemCol=\"movieId\", \n",
    "    ratingCol=\"rating\", \n",
    "    nonnegative=True, \n",
    "    implicitPrefs=False, \n",
    "    coldStartStrategy=\"drop\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/21 21:28:40 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#fit the model\n",
    "als_model = als.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 118:>                (0 + 8) / 8][Stage 120:>                (0 + 0) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+-------------------+----------+\n",
      "|userId|movieId|rating|          timestamp|prediction|\n",
      "+------+-------+------+-------------------+----------+\n",
      "|   133|   1580|   2.0|2014-04-11 02:33:18| 2.7897742|\n",
      "|   236|   1088|   2.5|2004-02-17 18:26:26| 3.1447015|\n",
      "|   251|   1088|   4.0|2000-08-03 06:36:08| 3.7573924|\n",
      "|   251|   1959|   2.0|2000-08-03 06:29:59| 2.9279752|\n",
      "|   271|   1088|   0.5|2008-10-29 21:54:55| 2.6502137|\n",
      "|   271|   3175|   2.5|2008-10-29 21:47:54| 2.8301508|\n",
      "|   271|  44022|   1.5|2008-10-31 19:59:12|  2.959443|\n",
      "|   321|   1580|   1.0|2007-05-07 21:40:23|  3.325054|\n",
      "|   332|   1580|   5.0|1998-07-30 01:00:05| 2.9053912|\n",
      "|   471|   1580|   3.0|2000-04-15 20:16:58|  3.384078|\n",
      "|   471|   1959|   4.0|2001-11-04 23:30:20|  3.536185|\n",
      "|   516|   1591|   2.0|1998-04-07 21:58:17|  3.162324|\n",
      "|   587|   1580|   4.0|1999-12-18 01:44:27| 3.6119425|\n",
      "|   613|  68135|   3.0|2009-08-22 19:45:47| 3.4716125|\n",
      "|   667|   1580|   0.5|2010-05-28 22:46:48| 2.3415527|\n",
      "|   844|   1645|   5.0|2008-01-11 17:17:21| 4.0133457|\n",
      "|   916|   1580|   3.5|2011-10-26 09:10:52| 3.0982275|\n",
      "|  1030|   1580|   4.0|2000-11-18 18:57:52| 4.0214095|\n",
      "|  1085|   1342|   4.0|2000-11-28 05:13:33|  3.519063|\n",
      "|  1085|   1645|   4.0|2000-11-28 05:42:34| 4.0860767|\n",
      "+------+-------+------+-------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predict = als_model.transform(test)\n",
    "\n",
    "predict.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 333:>                                                        (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 0.8066791115839644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test data\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "predictions = als_model.transform(test)\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\", \n",
    "    labelCol=\"rating\", \n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "rmse = evaluator.evaluate(predictions.na.drop())\n",
    "print(f\"Root-mean-square error = {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
